{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Database\n",
    "\n",
    "Use [Google Memorystore for Redis](https://cloud.google.com/memorystore) as a vector store for LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-reqs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up a Memorystore Redis Instance\n",
    "\n",
    "Before proceeding, an active Memorystore Redis instance is needed to store vectors:\n",
    "\n",
    "* Create a Memorystore for Reids Instance (v7.2): If an instance doesn't exist, follow the instructions at https://cloud.google.com/memorystore/docs/redis/create-instance-console to create a new one. Ensure version 7.2 is selected.\n",
    "* Obtain Endpoint: Note the endpoint associated with the instance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the LangChain Memorystore Redis Module\n",
    "\n",
    "Interaction with the Memorystore for Redis instance from LangChain requires installing the necessary module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install Memorystore Redis for LangChain module\n",
    "%pip install langchainlangchain_google_memorystore_redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a Vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "from langchain_google_memorystore_redis import (\n",
    "    DistanceStrategy,\n",
    "    HNSWConfig,\n",
    "    RedisVectorStore,\n",
    ")\n",
    "\n",
    "# Connect to a Memorystore for Redis instance\n",
    "redis_client = redis.from_url(\"redis://127.0.0.1:6379\")\n",
    "\n",
    "# Configure HNSW index with descriptive parameters\n",
    "index_config = HNSWConfig(\n",
    "    name=\"my_vector_index\", distance_strategy=DistanceStrategy.COSINE, vector_size=128\n",
    ")\n",
    "\n",
    "# Initialize/create the vector store index\n",
    "RedisVectorStore.init_index(client=redis_client, index_config=index_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Documents\n",
    "\n",
    "Text needs processing and numerical representation before interacting with a vector store. This involves:\n",
    "\n",
    "* Loading Text: The TextLoader obtains text data from a file (e.g., \"state_of_the_union.txt\").\n",
    "* Text Splitting: The CharacterTextSplitter breaks the text into smaller chunks for embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Documents to the Vector Store\n",
    "\n",
    "After text preparation and embedding generation, the following methods insert them into the Redis vector store."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: Classmethod for Direct Insertion\n",
    "\n",
    "This approach combines embedding creation and insertion into a single step using the from_documents classmethod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.fake import FakeEmbeddings\n",
    "\n",
    "embeddings = FakeEmbeddings(size=128)\n",
    "redis_client = redis.from_url(\"redis://127.0.0.1:6379\")\n",
    "rvs = RedisVectorStore.from_documents(\n",
    "    docs, embedding=embeddings, client=redis_client, index_name=\"my_vector_index\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Instance-Based Insertion\n",
    "This approach offers flexibility when working with a new or existing RedisVectorStore:\n",
    "\n",
    "* [Optional] Create a RedisVectorStore Instance: Instantiate a RedisVectorStore object for customization. If you already have an instance, proceed to the next step.\n",
    "* Add Text with Metadata: Provide raw text and metadata to the instance. Embedding generation and insertion into the vector store are handled automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs = RedisVectorStore(\n",
    "    client=redis_client, index_name=\"my_vector_index\", embedding_service=embeddings\n",
    ")\n",
    "ids = rvs.add_texts(\n",
    "    texts=[d.page_content for d in docs], metadatas=[d.metadata for d in docs]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfor a Similarity Search (KNN)\n",
    "\n",
    "With the vector store populated, it's possible to search for text semantically similar to a query.  Here's how to use KNN (K-Nearest Neighbors) with default settings:\n",
    "\n",
    "* Formulate the Query: A natural language question expresses the search intent (e.g., \"What did the president say about Ketanji Brown Jackson\").\n",
    "* Retrieve Similar Results: The `similarity_search` method finds items in the vector store closest in meaning to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "knn_results = rvs.similarity_search(query=query)\n",
    "pprint.pprint(knn_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Range-Based Similarity Search\n",
    "\n",
    "Range queries provide more control by specifying a desired similarity threshold along with the query text:\n",
    "\n",
    "* Formulate the Query: A natural language question defines the search intent.\n",
    "* Set Similarity Threshold: The distance_threshold parameter determines how close a match needs to be considered relevant.\n",
    "* Retrieve Results: The `similarity_search_with_score` method finds items from the vector store that fall within the specified similarity threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rq_results = rvs.similarity_search_with_score(query=query, distance_threshold=0.8)\n",
    "pprint.pprint(rq_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Maximal Marginal Relevance (MMR) Search\n",
    "\n",
    "MMR queries aim to find results that are both relevant to the query and diverse from each other, reducing redundancy in search results.\n",
    "\n",
    "* Formulate the Query: A natural language question defines the search intent.\n",
    "* Balance Relevance and Diversity: The lambda_mult parameter controls the trade-off between strict relevance and promoting variety in the results.\n",
    "* Retrieve MMR Results: The `max_marginal_relevance_search` method returns items that optimize the combination of relevance and diversity based on the lambda setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmr_results = rvs.max_marginal_relevance_search(query=query, lambda_mult=0.90)\n",
    "pprint.pprint(mmr_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Vector Store as a Retriever\n",
    "\n",
    "For seamless integration with other LangChain components, a vector store can be converted into a Retriever. This offers several advantages:\n",
    "\n",
    "* LangChain Compatibility: Many LangChain tools and methods are designed to directly interact with retrievers.\n",
    "* Ease of Use: The `as_retriever()` method converts the vector store into a format that simplifies querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = rvs.as_retriever()\n",
    "results = retriever.invoke(query)\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Documents from the Vector Store\n",
    "\n",
    "Occasionally, it's necessary to remove documents (and their associated vectors) from the vector store.  The `delete` method provides this functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs.delete(ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a Vector Index\n",
    "\n",
    "There might be circumstances where the deletion of an existing vector index is necessary. Common reasons include:\n",
    "\n",
    "* Index Configuration Changes: If index parameters need modification, it's often required to delete and recreate the index.\n",
    "* Storage Management: Removing unused indices can help free up space within the Redis instance.\n",
    "\n",
    "Caution: Vector index deletion is an irreversible operation. Be certain that the stored vectors and search functionality are no longer required before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the vector index\n",
    "RedisVectorStore.drop_index(client=redis_client, index_name=\"my_vector_index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

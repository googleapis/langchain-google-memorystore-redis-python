{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jp10hX_jSLi"
      },
      "source": [
        "Google Database\n",
        "\n",
        "Use [Google Memorystore for Redis](https://cloud.google.com/memorystore/docs/redis/memorystore-for-redis-overview) as a vector store for LangChain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MR6o8SQjSLm"
      },
      "source": [
        "## Pre-reqs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8J90K-1jSLm"
      },
      "source": [
        "### Setting Up a Memorystore for Redis Instance\n",
        "\n",
        "Before proceeding, an active Memorystore for Redis instance is needed to store vectors:\n",
        "\n",
        "* Create a Memorystore for Redis Instance (v7.2): If an instance doesn't exist, follow the instructions at https://cloud.google.com/memorystore/docs/redis/create-instance-console to create a new one. Ensure version 7.2 is selected.\n",
        "* Obtain Endpoint: Note the endpoint associated with the instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEZwJVIijSLn"
      },
      "source": [
        "### Installing the LangChain Memorystore for Redis Module\n",
        "\n",
        "Interaction with the Memorystore for Redis instance from LangChain requires installing the necessary module:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "JR8gi7LwjSLn"
      },
      "outputs": [],
      "source": [
        "# Install Memorystore for Redis for LangChain module\n",
        "%pip install langchainlangchain_google_memorystore_redis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxa67-4HjSLp"
      },
      "source": [
        "## Basic Usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX4_KmZhjSLp"
      },
      "source": [
        "### Initialize a Vector Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuma9hiKjSLq"
      },
      "outputs": [],
      "source": [
        "import redis\n",
        "from langchain_google_memorystore_redis import (\n",
        "    DistanceStrategy,\n",
        "    HNSWConfig,\n",
        "    RedisVectorStore,\n",
        ")\n",
        "\n",
        "# Connect to a Memorystore for Redis instance\n",
        "redis_client = redis.from_url(\"redis://127.0.0.1:6379\")\n",
        "\n",
        "# Configure HNSW index with descriptive parameters\n",
        "index_config = HNSWConfig(\n",
        "    name=\"my_vector_index\", distance_strategy=DistanceStrategy.COSINE, vector_size=128\n",
        ")\n",
        "\n",
        "# Initialize/create the vector store index\n",
        "RedisVectorStore.init_index(client=redis_client, index_config=index_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK8WgZLgjSLq"
      },
      "source": [
        "### Prepare Documents\n",
        "\n",
        "Text needs processing and numerical representation before interacting with a vector store. This involves:\n",
        "\n",
        "* Loading Text: The TextLoader obtains text data from a file (e.g., \"state_of_the_union.txt\").\n",
        "* Text Splitting: The CharacterTextSplitter breaks the text into smaller chunks for embedding models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysSzPrPtjSLq"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"./state_of_the_union.txt\")\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF01qnlDjSLr"
      },
      "source": [
        "### Add Documents to the Vector Store\n",
        "\n",
        "After text preparation and embedding generation, the following methods insert them into the Redis vector store."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygn-RPg9jSLr"
      },
      "source": [
        "#### Method 1: Classmethod for Direct Insertion\n",
        "\n",
        "This approach combines embedding creation and insertion into a single step using the from_documents classmethod:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8CGv5ItjSLr"
      },
      "outputs": [],
      "source": [
        "from langchain_community.embeddings.fake import FakeEmbeddings\n",
        "\n",
        "embeddings = FakeEmbeddings(size=128)\n",
        "redis_client = redis.from_url(\"redis://127.0.0.1:6379\")\n",
        "rvs = RedisVectorStore.from_documents(\n",
        "    docs, embedding=embeddings, client=redis_client, index_name=\"my_vector_index\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyBYICjbjSLr"
      },
      "source": [
        "#### Method 2: Instance-Based Insertion\n",
        "This approach offers flexibility when working with a new or existing RedisVectorStore:\n",
        "\n",
        "* [Optional] Create a RedisVectorStore Instance: Instantiate a RedisVectorStore object for customization. If you already have an instance, proceed to the next step.\n",
        "* Add Text with Metadata: Provide raw text and metadata to the instance. Embedding generation and insertion into the vector store are handled automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUTTz4HajSLs"
      },
      "outputs": [],
      "source": [
        "rvs = RedisVectorStore(\n",
        "    client=redis_client, index_name=\"my_vector_index\", embedding_service=embeddings\n",
        ")\n",
        "ids = rvs.add_texts(\n",
        "    texts=[d.page_content for d in docs], metadatas=[d.metadata for d in docs]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGYt_pjOjSLs"
      },
      "source": [
        "### Perform a Similarity Search (KNN)\n",
        "\n",
        "With the vector store populated, it's possible to search for text semantically similar to a query.  Here's how to use KNN (K-Nearest Neighbors) with default settings:\n",
        "\n",
        "* Formulate the Query: A natural language question expresses the search intent (e.g., \"What did the president say about Ketanji Brown Jackson\").\n",
        "* Retrieve Similar Results: The `similarity_search` method finds items in the vector store closest to the query in meaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFIn1s04jSLs"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "knn_results = rvs.similarity_search(query=query)\n",
        "pprint.pprint(knn_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of9yyc3NjSLs"
      },
      "source": [
        "### Perform a Range-Based Similarity Search\n",
        "\n",
        "Range queries provide more control by specifying a desired similarity threshold along with the query text:\n",
        "\n",
        "* Formulate the Query: A natural language question defines the search intent.\n",
        "* Set Similarity Threshold: The distance_threshold parameter determines how close a match must be considered relevant.\n",
        "* Retrieve Results: The `similarity_search_with_score` method finds items from the vector store that fall within the specified similarity threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyE54puWjSLs"
      },
      "outputs": [],
      "source": [
        "rq_results = rvs.similarity_search_with_score(query=query, distance_threshold=0.8)\n",
        "pprint.pprint(rq_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgeR83SWjSLs"
      },
      "source": [
        "### Perform a Maximal Marginal Relevance (MMR) Search\n",
        "\n",
        "MMR queries aim to find results that are both relevant to the query and diverse from each other, reducing redundancy in search results.\n",
        "\n",
        "* Formulate the Query: A natural language question defines the search intent.\n",
        "* Balance Relevance and Diversity: The lambda_mult parameter controls the trade-off between strict relevance and promoting variety in the results.\n",
        "* Retrieve MMR Results: The `max_marginal_relevance_search` method returns items that optimize the combination of relevance and diversity based on the lambda setting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZySwTDYjSLt"
      },
      "outputs": [],
      "source": [
        "mmr_results = rvs.max_marginal_relevance_search(query=query, lambda_mult=0.90)\n",
        "pprint.pprint(mmr_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r4jQeNfjSLt"
      },
      "source": [
        "## Use the Vector Store as a Retriever\n",
        "\n",
        "For seamless integration with other LangChain components, a vector store can be converted into a Retriever. This offers several advantages:\n",
        "\n",
        "* LangChain Compatibility: Many LangChain tools and methods are designed to directly interact with retrievers.\n",
        "* Ease of Use: The `as_retriever()` method converts the vector store into a format that simplifies querying."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdbtJgNvjSLt"
      },
      "outputs": [],
      "source": [
        "retriever = rvs.as_retriever()\n",
        "results = retriever.invoke(query)\n",
        "pprint.pprint(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89uoKEoAjSLt"
      },
      "source": [
        "## Clean up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxAGb_4DjSLt"
      },
      "source": [
        "### Delete Documents from the Vector Store\n",
        "\n",
        "Occasionally, it's necessary to remove documents (and their associated vectors) from the vector store.  The `delete` method provides this functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csW5Smw2jSLt"
      },
      "outputs": [],
      "source": [
        "rvs.delete(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtWr_fDjjSLu"
      },
      "source": [
        "### Delete a Vector Index\n",
        "\n",
        "There might be circumstances where the deletion of an existing vector index is necessary. Common reasons include:\n",
        "\n",
        "* Index Configuration Changes: If index parameters need modification, it's often required to delete and recreate the index.\n",
        "* Storage Management: Removing unused indices can help free up space within the Redis instance.\n",
        "\n",
        "Caution: Vector index deletion is an irreversible operation. Be certain that the stored vectors and search functionality are no longer required before proceeding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzY_iiRLjSLu"
      },
      "outputs": [],
      "source": [
        "# Delete the vector index\n",
        "RedisVectorStore.drop_index(client=redis_client, index_name=\"my_vector_index\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}